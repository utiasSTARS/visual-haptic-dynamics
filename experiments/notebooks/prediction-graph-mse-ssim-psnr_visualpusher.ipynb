{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import _pickle as pkl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, time\n",
    "sys.path.append('../..')\n",
    "from utils import set_seed_torch, rgb2gray, load_vh_models, frame_stack\n",
    "set_seed_torch(3)\n",
    "from train import encode\n",
    "from argparse import Namespace\n",
    "import json\n",
    "import gzip\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectView(object):\n",
    "    def __init__(self, d): self.__dict__ = d\n",
    "        \n",
    "args = ObjectView({\n",
    " 'res': 64,\n",
    " 'dataset_path': ['/home/olimoyo/visual-haptic-dynamics/experiments/data/datasets/{}'\n",
    "                   .format(\"vha1_2D_len16_oscxy_withGT_0B7AB071F98942578ABDA66879290F2F.pkl\"),\n",
    "                  '/home/olimoyo/visual-haptic-dynamics/experiments/data/datasets/{}'\n",
    "                   .format(\"vha2_2D_len16_oscxy_withGT_3502DE81F7C343FB8B57FA92FDECF4DA.pkl\"),\n",
    "                  '/home/olimoyo/visual-haptic-dynamics/experiments/data/datasets/{}'\n",
    "                   .format(\"vha3_2D_len16_oscxy_withGT_5DB32B21A6AA4E5892D2F6B8F40EF9E6.pkl\")\n",
    "                 ],\n",
    " 'models_dir': '/home/olimoyo/visual-haptic-dynamics/saved_models/{}'\n",
    "                   .format(\"vh\"),\n",
    "#  'dataset_path': ['/home/olimoyo/visual-haptic-dynamics/experiments/data/datasets/mit_push/{}'\n",
    "#                    .format(\"min-tr2.5_min-rot0.5_len48.pkl\")\n",
    "#                  ],\n",
    "#  'models_dir': '/home/olimoyo/visual-haptic-dynamics/saved_models/{}'\n",
    "#                    .format(\"mit\"),\n",
    " 'device': 'cuda:1',\n",
    " 'up_to_n_pred': 12,\n",
    " 'n_initial': 2,\n",
    " 'n_final': 2\n",
    "})\n",
    "\n",
    "def load_models_dir(models_dir):\n",
    "    \"\"\"Load hyperparameters from trained model.\"\"\"\n",
    "    dict_of_models = {}\n",
    "    for filedir in os.listdir(models_dir):\n",
    "        fullpath = os.path.join(models_dir, filedir)\n",
    "        if os.path.isdir(fullpath):\n",
    "            with open(os.path.join(fullpath, 'hyperparameters.txt'), 'r') as fp:\n",
    "                dict_of_models[fullpath] = Namespace(**json.load(fp))\n",
    "    return dict_of_models\n",
    "\n",
    "def is_gz_file(filepath):\n",
    "    with open(filepath, 'rb') as test_f:\n",
    "        return test_f.read(2) == b'\\x1f\\x8b'\n",
    "    \n",
    "data = {\n",
    "#     'img_rgb': [],\n",
    "    'img_gray': [],\n",
    "    'haptic': [],\n",
    "    'arm': [],\n",
    "    'actions': []\n",
    "}\n",
    "\n",
    "for dataset_path in args.dataset_path:\n",
    "    if is_gz_file(dataset_path):\n",
    "        with gzip.open(dataset_path, 'rb') as f:\n",
    "            raw_data = pkl.load(f)\n",
    "    else:\n",
    "        with open(dataset_path, 'rb') as f:\n",
    "            raw_data = pkl.load(f)\n",
    "\n",
    "#     data['img_rgb'].append(torch.from_numpy(raw_data[\"img\"].transpose(0, 1, 4, 2, 3)).int().to(device=args.device))\n",
    "    data['img_gray'].append(torch.from_numpy(rgb2gray(raw_data[\"img\"]).transpose(0, 1, 4, 2, 3)).float().to(device=args.device))\n",
    "    data['haptic'].append(torch.from_numpy(raw_data['ft']).float().to(device=args.device))\n",
    "    data['arm'].append(torch.from_numpy(raw_data['arm']).float().to(device=args.device))\n",
    "    data['actions'].append(torch.from_numpy(raw_data[\"action\"]).to(device=args.device).float())\n",
    "\n",
    "data = {k:torch.cat(v, dim=0) for k,v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_of_models = load_models_dir(args.models_dir)\n",
    "analysis_data = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for path, model_args in dict_of_models.items():\n",
    "        \n",
    "        model_name = path.split(\"/\")[-1]\n",
    "        nets = load_vh_models(path=path, args=model_args, mode='eval', device=args.device)\n",
    "        \n",
    "        # Use validation indices only\n",
    "        with open(os.path.join(path, \"val_idx.pkl\"), 'rb') as f:\n",
    "            val_idx = pkl.load(f)\n",
    "        data_val = {k:v[val_idx] for k,v in data.items()}\n",
    "    \n",
    "#         if model_args.dim_x[0] == 1:\n",
    "#             imgs = data['img_gray']\n",
    "#         elif model_args.dim_x[0] == 3:\n",
    "#             imgs = data['img_rgb']\n",
    "        img_key = 'img_gray'\n",
    "\n",
    "        T = model_args.frame_stacks\n",
    "\n",
    "        assert args.n_initial + args.up_to_n_pred <= data_val[img_key].shape[1]\n",
    "        assert args.n_initial > T\n",
    "        \n",
    "        x_i = {}\n",
    "        x_gt = {}\n",
    "        \n",
    "        analysis_data[model_name] = {}\n",
    "        for n_pred in range(1, args.up_to_n_pred + 1):\n",
    "            analysis_data[model_name][f\"{n_pred}_pred\"] = {\n",
    "                \"MSE_x\": {\"mu\": 0, \"std\": 0},\n",
    "                \"MSE_z\": {\"mu\": 0, \"std\": 0},\n",
    "                \"SSIM\": {\"mu\": 0, \"std\": 0},\n",
    "                \"PSNR\": {\"mu\": 0, \"std\": 0}\n",
    "            }\n",
    "            \n",
    "            u = data_val['actions']\n",
    "\n",
    "            # Sequence of initial images\n",
    "            x_img_i = data_val[img_key][:, :args.n_initial] \n",
    "            x_img_i = frame_stack(x_img_i, frames=T)\n",
    "            n, l = x_img_i.shape[0], x_img_i.shape[1] \n",
    "            x_i[\"img\"] = x_img_i\n",
    "\n",
    "            # Sequence of initial extra modalities\n",
    "            x_ft_i = data_val['haptic'][:, :args.n_initial] / model_args.ft_normalization\n",
    "            x_arm_i = data_val['arm'][:, :args.n_initial]               \n",
    "            u_i = u[:, T:args.n_initial]\n",
    "\n",
    "            if model_args.context_modality != \"none\":\n",
    "                if model_args.context_modality == \"joint\":\n",
    "                    x_i[\"context\"] = torch.cat((x_ft_i, x_arm_i), dim=-1)\n",
    "                elif model_args.context_modality == \"ft\":\n",
    "                    x_i[\"context\"] = x_ft_i\n",
    "                elif model_args.context_modality == \"arm\":\n",
    "                    x_i[\"context\"] = x_arm_i\n",
    "\n",
    "                if model_args.use_context_frame_stack:\n",
    "                    x_i['context'] = frame_stack(x_i['context'], frames=T)\n",
    "                else:\n",
    "                    x_i[\"context\"] = x_i[\"context\"][:, T:]\n",
    "                x_i[\"context\"] = x_i[\"context\"].transpose(-1, -2)\n",
    "            x_i = {k:v.reshape(-1, *v.shape[2:]) for k, v in x_i.items()}\n",
    "\n",
    "            # Sequence of gt images\n",
    "            x_img_gt = data_val[img_key][:, (args.n_initial + n_pred - args.n_final):(args.n_initial + n_pred)]\n",
    "            x_img_gt = frame_stack(x_img_gt, frames=T)\n",
    "            l_gt = x_img_gt.shape[1]\n",
    "            x_gt[\"img\"] = x_img_gt\n",
    "            \n",
    "            # Sequence of gt extra modalities\n",
    "            x_ft_gt = data_val['haptic'][:, (args.n_initial + n_pred - args.n_final):(args.n_initial + n_pred)] / model_args.ft_normalization\n",
    "            x_arm_gt = data_val['arm'][:, (args.n_initial + n_pred - args.n_final):(args.n_initial + n_pred)]\n",
    "            u_gt = u[:, (args.n_initial + n_pred - args.n_final + T):(args.n_initial + n_pred)]\n",
    "            \n",
    "            if model_args.context_modality != \"none\":\n",
    "                if model_args.context_modality == \"joint\":\n",
    "                    x_gt[\"context\"] = torch.cat((x_ft_gt, x_arm_gt), dim=-1)\n",
    "                elif model_args.context_modality == \"ft\":\n",
    "                    x_gt[\"context\"] = x_ft_gt\n",
    "                elif model_args.context_modality == \"arm\":\n",
    "                    x_gt[\"context\"] = x_arm_gt\n",
    "\n",
    "                if model_args.use_context_frame_stack:\n",
    "                    x_gt['context'] = frame_stack(x_gt['context'], frames=T)\n",
    "                else:\n",
    "                    x_gt[\"context\"] = x_gt[\"context\"][:, T:]\n",
    "                x_gt[\"context\"] = x_gt[\"context\"].transpose(-1, -2)\n",
    "            x_gt = {k:v.reshape(-1, *v.shape[2:]) for k, v in x_gt.items()}\n",
    "\n",
    "            # Encode\n",
    "            if model_args.use_prior_expert:\n",
    "                q_z_i, _ = encode(nets, model_args, x_i, u_i, device=args.device)\n",
    "                q_z_gt, _ = encode(nets, model_args, x_gt, u_gt, device=args.device)\n",
    "            else:\n",
    "                q_z_i = encode(nets, model_args, x_i, u_i, device=args.device)\n",
    "                q_z_gt = encode(nets, model_args, x_gt, u_gt, device=args.device)\n",
    "            \n",
    "            z_gt = q_z_g[\"mu\"]\n",
    "            z_gt = z_gt.reshape(n, l_gt, -1)[:, -1]\n",
    "            \n",
    "            # Group and prepare for prediction\n",
    "            q_z_i = {k:v.reshape(n, l, *v.shape[1:]).transpose(1,0) for k, v in q_z_i.items()}\n",
    "            u = u.transpose(1,0)\n",
    "\n",
    "            # First run\n",
    "            z_i, mu_z_i, var_z_i = q_z_i[\"z\"], q_z_i[\"mu\"], q_z_i[\"cov\"]\n",
    "            u_i = u[(T + 1):(1 + args.n_initial)]\n",
    "            h_i = None\n",
    "\n",
    "            # Predict\n",
    "            for jj in range(0, n_pred):\n",
    "                z_ip1, mu_z_ip1, var_z_ip1, h_ip1 = nets[\"dyn\"](\n",
    "                    z_t=z_i, \n",
    "                    mu_t=mu_z_i, \n",
    "                    var_t=var_z_i, \n",
    "                    u=u_i, \n",
    "                    h_0=h_i, \n",
    "                    single=False\n",
    "                )\n",
    "                z_hat = mu_z_ip1[-1]\n",
    "                z_i, mu_z_i, var_z_i, h_i = z_ip1[-1:], mu_z_ip1[-1:], var_z_ip1[-1:], h_ip1\n",
    "                u_i = u[1 + args.n_initial + jj][None]\n",
    "            \n",
    "            # Decode \n",
    "            x_hat = nets[\"img_dec\"](z_hat)\n",
    "            x_hat = x_hat[:, 0].view(x_hat.shape[0], -1)\n",
    "            x_img_gt = x_img_gt[:, -1, 0].view(x_img_gt.shape[0], -1)\n",
    "            \n",
    "            # Move to cpu, np\n",
    "            x_hat = x_hat.cpu().numpy()\n",
    "            z_hat = z_hat.cpu().numpy()\n",
    "            x_img_gt = x_img_gt.cpu().numpy()\n",
    "            z_gt = z_gt.cpu().numpy()\n",
    "            \n",
    "            batch_mse_img = np.sum(((x_img_gt - x_hat)**2), axis=-1)\n",
    "            batch_mse_z = np.sum(((z_gt - z_hat)**2), axis=-1)\n",
    "            print(\"prediction length\", n_pred, \"starting position\", T,\n",
    "                \"mean mse img: \", batch_mse_img.mean(),\n",
    "                \"std mse img: \", batch_mse_img.std(),\n",
    "                \"mean mse latent: \", batch_mse_z.mean(),\n",
    "                \"std mse latent: \", batch_mse_z.std())\n",
    "\n",
    "            analysis_data[model_name][f\"{n_pred}_pred\"][\"MSE_x\"][\"mu\"] = batch_mse_img.mean()\n",
    "            analysis_data[model_name][f\"{n_pred}_pred\"][\"MSE_x\"][\"std\"] = batch_mse_img.std()\n",
    "            analysis_data[model_name][f\"{n_pred}_pred\"][\"MSE_z\"][\"mu\"] = batch_mse_z.mean()\n",
    "            analysis_data[model_name][f\"{n_pred}_pred\"][\"MSE_z\"][\"std\"] = batch_mse_z.std()\n",
    "\n",
    "\n",
    "            batch_ssim = []\n",
    "            batch_psnr = []\n",
    "            for jj in range(n):\n",
    "                batch_ssim.append(ssim(\n",
    "                    x_img_gt[jj].reshape(64,64), \n",
    "                    x_hat[jj].reshape(64,64), \n",
    "                    data_range=1.0\n",
    "                ))\n",
    "                batch_psnr.append(psnr(\n",
    "                    x_img_gt[jj].reshape(64,64), \n",
    "                    x_hat[jj].reshape(64,64), \n",
    "                    data_range=1.0\n",
    "                ))\n",
    "            batch_ssim = np.array(batch_ssim)\n",
    "            batch_psnr = np.array(batch_psnr)\n",
    "\n",
    "            analysis_data[model_name][f\"{n_pred}_pred\"][\"SSIM\"][\"mu\"] = batch_ssim.mean()\n",
    "            analysis_data[model_name][f\"{n_pred}_pred\"][\"SSIM\"][\"std\"] = batch_ssim.std()\n",
    "            analysis_data[model_name][f\"{n_pred}_pred\"][\"PSNR\"][\"mu\"] = batch_psnr.mean()\n",
    "            analysis_data[model_name][f\"{n_pred}_pred\"][\"PSNR\"][\"std\"] = batch_psnr.std()\n",
    "\n",
    "\n",
    "    print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def add_data_to_plot(name, data, var=True):\n",
    "    if \"_vha_\" in name:\n",
    "        color = '#ff7f0e'\n",
    "    elif \"_v_\" in name:\n",
    "        color = '#1f77b4'\n",
    "    elif \"_va_\" in name:\n",
    "        color = 'red'\n",
    "    elif \"_vh_\" in name:\n",
    "        color = 'green'\n",
    "    elif \"prior_expert\" in name:\n",
    "        return\n",
    "        \n",
    "    if \"nstep2\" in name:\n",
    "        marker = \"o\"\n",
    "    else:\n",
    "        marker = \"x\"\n",
    "    \n",
    "    plot_data = {'MSE_x': {\"mu\":[], \"std\":[]}, \n",
    "                 'SSIM': {\"mu\":[], \"std\":[]}, \n",
    "                 'PSNR': {\"mu\":[], \"std\":[]}, \n",
    "                 \"MSE_z\": {\"mu\":[], \"std\":[]}}\n",
    "    for k, v in data.items():\n",
    "        plot_data['MSE_x'][\"mu\"].append(v['MSE_x'][\"mu\"])\n",
    "        plot_data['MSE_x'][\"std\"].append(v['MSE_x'][\"std\"])\n",
    "        plot_data['SSIM'][\"mu\"].append(v['SSIM'][\"mu\"])\n",
    "        plot_data['SSIM'][\"std\"].append(v['SSIM'][\"std\"])\n",
    "        plot_data['PSNR'][\"mu\"].append(v['PSNR'][\"mu\"])\n",
    "        plot_data['PSNR'][\"std\"].append(v['PSNR'][\"std\"])\n",
    "        plot_data['MSE_z'][\"mu\"].append(v['MSE_z'][\"mu\"])\n",
    "        plot_data['MSE_z'][\"std\"].append(v['MSE_z'][\"std\"])\n",
    "\n",
    "    custom_lines = [Line2D([0], [0], color='#ff7f0e', lw=4),\n",
    "                    Line2D([0], [0], color='#1f77b4', lw=4),\n",
    "                    Line2D([0], [0], color='red', lw=4),\n",
    "                    Line2D([0], [0], color='green', lw=4),\n",
    "                    Line2D([0], [0], color='black', lw=1, marker=\"o\"),\n",
    "                    Line2D([0], [0], color='black', lw=1, marker=\"x\")]\n",
    "\n",
    "    axs[0,0].legend(\n",
    "        custom_lines, \n",
    "        ['Visual-Haptic-Proprio',\n",
    "         'Visual',\n",
    "         'Visual-Propio',\n",
    "         'Visual-Haptic'], \n",
    "        loc='upper left'\n",
    "    )\n",
    "\n",
    "    axs[0,0].plot(\n",
    "        list(range(1, len(plot_data['MSE_x'][\"mu\"]) + 1)), \n",
    "        plot_data['MSE_x'][\"mu\"],\n",
    "        color=color, \n",
    "        marker=marker,\n",
    "    )\n",
    "    if var:\n",
    "        axs[0,0].fill_between(\n",
    "            list(range(1, len(plot_data['MSE_x'][\"mu\"]) + 1)), \n",
    "            [a_i + b_i for a_i, b_i in zip(plot_data['MSE_x'][\"mu\"], plot_data['MSE_x'][\"std\"])],\n",
    "            [a_i - b_i for a_i, b_i in zip(plot_data['MSE_x'][\"mu\"], plot_data['MSE_x'][\"std\"])],\n",
    "            facecolor=color, \n",
    "            alpha=0.35\n",
    "        )\n",
    "    axs[0,1].plot(\n",
    "        list(range(1, len(plot_data['SSIM'][\"mu\"]) + 1)), \n",
    "        plot_data['SSIM'][\"mu\"],\n",
    "        color=color, \n",
    "        marker=marker\n",
    "    )\n",
    "    if var:\n",
    "        axs[0,1].fill_between(\n",
    "            list(range(1, len(plot_data['SSIM'][\"mu\"]) + 1)), \n",
    "            [a_i + b_i for a_i, b_i in zip(plot_data['SSIM'][\"mu\"], plot_data['SSIM'][\"std\"])],\n",
    "            [a_i - b_i for a_i, b_i in zip(plot_data['SSIM'][\"mu\"], plot_data['SSIM'][\"std\"])],\n",
    "            facecolor=color, \n",
    "            alpha=0.35\n",
    "        )\n",
    "        \n",
    "    axs[1,0].plot(\n",
    "        list(range(1, len(plot_data['PSNR'][\"mu\"]) + 1)), \n",
    "        plot_data['PSNR'][\"mu\"],\n",
    "        color=color,\n",
    "        marker=marker\n",
    "    )\n",
    "    if var:\n",
    "        axs[1,0].fill_between(\n",
    "            list(range(1, len(plot_data['PSNR'][\"mu\"]) + 1)), \n",
    "            [a_i + b_i for a_i, b_i in zip(plot_data['PSNR'][\"mu\"], plot_data['PSNR'][\"std\"])],\n",
    "            [a_i - b_i for a_i, b_i in zip(plot_data['PSNR'][\"mu\"], plot_data['PSNR'][\"std\"])],\n",
    "            facecolor=color, \n",
    "            alpha=0.35\n",
    "        )\n",
    "    axs[1,1].plot(\n",
    "        list(range(1, len(plot_data['MSE_z'][\"mu\"]) + 1)), \n",
    "        plot_data['MSE_z'][\"mu\"],\n",
    "        color=color,\n",
    "        marker=marker\n",
    "    )\n",
    "    if var:\n",
    "        axs[1,1].fill_between(\n",
    "            list(range(1, len(plot_data['MSE_z'][\"mu\"]) + 1)), \n",
    "            [a_i + b_i for a_i, b_i in zip(plot_data['MSE_z'][\"mu\"], plot_data['MSE_z'][\"std\"])],\n",
    "            [a_i - b_i for a_i, b_i in zip(plot_data['MSE_z'][\"mu\"], plot_data['MSE_z'][\"std\"])],\n",
    "            facecolor=color, \n",
    "            alpha=0.35\n",
    "        )\n",
    "    \n",
    "    for ii in range(axs.shape[0]):\n",
    "        for jj in range(axs.shape[1]):\n",
    "            axs[ii, jj].set_xlabel(\"Timesteps predicted\", fontsize=18)\n",
    "            axs[ii, jj].set_xticks(np.arange(1, args.up_to_n_pred + 1, 1.0))\n",
    "            axs[ii, jj].grid(alpha=0.35, linestyle='solid', axis='both')\n",
    "\n",
    "    axs[0, 0].set_ylabel(\"MSE (Image space)\", fontsize=18)\n",
    "    axs[0, 1].set_ylabel(\"Average SSIM\", fontsize=18)\n",
    "    axs[1, 0].set_ylabel(\"Average PSNR [dB]\", fontsize=18)\n",
    "    axs[1, 1].set_ylabel(\"MSE (Latent space)\", fontsize=18)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16,12))\n",
    "for k, v in analysis_data.items():\n",
    "    print(k)\n",
    "    add_data_to_plot(k, v, var=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
