{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import _pickle as pkl\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys, time\n",
    "sys.path.append('../..')\n",
    "from utils import set_seed_torch, rgb2gray\n",
    "set_seed_torch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectView(object):\n",
    "    def __init__(self, d): self.__dict__ = d\n",
    "        \n",
    "args = ObjectView({'res': 64,\n",
    " 'dataset_path': '/home/olimoyo/visual-haptic-dynamics/experiments/data/datasets/{}'\n",
    "                   .format(\"visual_haptic_2D_len16_569B46785E3F45BCA172AE53EA070D5E.pkl\"),\n",
    " 'models_dir': '/home/olimoyo/visual-haptic-dynamics/saved_models/{}'\n",
    "                   .format(\"test\"),\n",
    " 'device': 'cuda:0',\n",
    " 'up_to_n_pred': 6,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.dataset_path, 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "x = {}\n",
    "x['img_rgb'] = torch.from_numpy(data[\"img\"].transpose(0, 1, 4, 2, 3)).int().to(device=args.device)\n",
    "x['img_gray'] = torch.from_numpy(rgb2gray(data[\"img\"]).transpose(0, 1, 4, 2, 3)).float().to(device=args.device)\n",
    "x['haptic'] = torch.from_numpy(data['ft']).float().to(device=args.device)\n",
    "x['arm'] = torch.from_numpy(data['arm']).float().to(device=args.device)\n",
    "\n",
    "actions = torch.from_numpy(data[\"action\"]).to(device=args.device).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1408, 16, 3, 64, 64])\n",
      "torch.Size([1408, 16, 1, 64, 64])\n",
      "torch.Size([1408, 16, 32, 6])\n",
      "torch.Size([1408, 16, 32, 6])\n",
      "torch.Size([1408, 16, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x['img_rgb'].shape)\n",
    "print(x['img_gray'].shape)\n",
    "print(x['haptic'].shape)\n",
    "print(x['arm'].shape)\n",
    "print(actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_vh_models, frame_stack\n",
    "from argparse import Namespace\n",
    "import json\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models in path:  /home/olimoyo/visual-haptic-dynamics/saved_models/test/2D_lightTCN_base_gru_lm_vha\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "# Load hyperparameters from trained model\n",
    "for filedir in os.listdir(args.models_dir):\n",
    "    fullpath = os.path.join(args.models_dir, filedir)\n",
    "    if os.path.isdir(fullpath):\n",
    "        models[fullpath] = {}\n",
    "        with open(os.path.join(fullpath, 'hyperparameters.txt'), 'r') as fp:\n",
    "            models[fullpath]['hyperparameters'] = Namespace(**json.load(fp))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for path, model in models.items():\n",
    "        model_args = model['hyperparameters']\n",
    "        models = load_vh_models(path, model_args, mode='eval', device=args.device)\n",
    "\n",
    "        if model_args.dim_x[0] == 1:\n",
    "            imgs = x['img_gray']\n",
    "        elif model_args.dim_x[0] == 3:\n",
    "            imgs = x['img_rgb']\n",
    "        \n",
    "        total_len = imgs.shape[1]\n",
    "        T = model_args.frame_stacks\n",
    "                    \n",
    "        data = {}\n",
    "        for n_pred in range(1, args.up_to_n_pred):\n",
    "            data[f\"{n_pred}_pred\"] = {}\n",
    "            data[f\"{n_pred}_pred\"][\"MSE\"] = 0\n",
    "            data[f\"{n_pred}_pred\"][\"SSIM\"] = 0\n",
    "            data[f\"{n_pred}_pred\"][\"PSNR\"] = 0\n",
    "            \n",
    "            for ii in range(T, total_len - n_pred):\n",
    "                x_i = imgs[:, (ii - 1):(ii + 1)] \n",
    "                x_i = frame_stack(x_i, frames=T)  \n",
    "                \n",
    "                x_ft_i = x['haptic'][:, ii:(ii + 1)] \n",
    "                x_arm_i = x['arm'][:, ii:(ii + 1)] \n",
    "                \n",
    "                x_gt = imgs[:, (ii + n_pred)]\n",
    "                u = actions[:, (ii + 1):(ii + n_pred + 1)]\n",
    "                \n",
    "                # Encode\n",
    "                z_all = []\n",
    "                if model_args.use_img_enc:\n",
    "                    z_all.append(models[\"img_enc\"](x_i.reshape(-1, *x_i.shape[2:])))\n",
    "\n",
    "                if model_args.use_joint_enc:\n",
    "                    joint_inp = torch.cat((\n",
    "                        x_ft_i.reshape(-1, *x_ft_i.shape[2:]), \n",
    "                        x_arm_i.reshape(-1, *x_arm_i.shape[2:])), \n",
    "                        dim=-1\n",
    "                    )\n",
    "                    z_all.append(models[\"joint_enc\"](joint_inp)[:, -1])\n",
    "                else:\n",
    "                    if model_args.use_haptic_enc:\n",
    "                        z_all.append(models[\"haptic_enc\"](x_ft_i.reshape(-1, *x_ft_i.shape[2:]))[:, -1])\n",
    "                    if model_args.use_arm_enc:\n",
    "                        z_all.append(models[\"arm_enc\"](x_arm_i.reshape(-1, *x_arm_i.shape[2:]))[:, -1])\n",
    "                \n",
    "                z_cat_i = torch.cat(z_all, dim=1)\n",
    "                z_i, mu_z_i, logvar_z_i = models[\"mix\"](z_cat_i)\n",
    "                var_z_i = torch.diag_embed(torch.exp(logvar_z_i))\n",
    "                \n",
    "                # Predict\n",
    "                h_i = None\n",
    "                for jj in range(n_pred):\n",
    "                    z_ip1, mu_z_ip1, var_z_ip1, h_ip1 = models[\"dyn\"](\n",
    "                        z_t=z_i, \n",
    "                        mu_t=mu_z_i, \n",
    "                        var_t=var_z_i, \n",
    "                        u=u[:, jj], \n",
    "                        h=h_i, \n",
    "                        single=True\n",
    "                    )\n",
    "                    z_i, mu_z_i, var_z_i, h_i = z_ip1, mu_z_ip1, var_z_ip1, h_ip1    \n",
    "\n",
    "                # Decode \n",
    "                x_hat = models[\"img_dec\"](z_ip1)\n",
    "\n",
    "                # TODO: Calculate MSE/SSIM/PSNR for single prediction\n",
    "                x_hat = x_hat[:, 0:1]\n",
    "\n",
    "                data[f\"{n_pred}_pred\"][\"MSE\"] += 0\n",
    "                data[f\"{n_pred}_pred\"][\"SSIM\"] += 0\n",
    "                data[f\"{n_pred}_pred\"][\"PSNR\"] += 0\n",
    "                \n",
    "            \n",
    "            # Average MSE/SSIM/PSNR\n",
    "            for k in data[f\"{n_pred}_pred\"]:\n",
    "                data[f\"{n_pred}_pred\"][k] /= total_len - n_pred - 1\n",
    "    print(\"DONE\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1_pred': {'MSE': 0.0, 'SSIM': 0.0, 'PSNR': 0.0}, '2_pred': {'MSE': 0.0, 'SSIM': 0.0, 'PSNR': 0.0}, '3_pred': {'MSE': 0.0, 'SSIM': 0.0, 'PSNR': 0.0}, '4_pred': {'MSE': 0.0, 'SSIM': 0.0, 'PSNR': 0.0}, '5_pred': {'MSE': 0.0, 'SSIM': 0.0, 'PSNR': 0.0}}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
