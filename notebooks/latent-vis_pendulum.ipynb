{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import _pickle as pkl\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import random\n",
    "import os, sys, time\n",
    "sys.path.append('..')\n",
    "from utils import (set_seed_torch, Normalize)\n",
    "set_seed_torch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectView(object):\n",
    "    def __init__(self, d): self.__dict__ = d\n",
    "\n",
    "args = ObjectView({'res': 64,\n",
    " 'dataset_path': '/media/m2-drive/datasets/pendulum-srl-sim/{}'\n",
    "                   .format(\"pendulum64_total_2048_traj_16_repeat_2_with_angle_train.pkl\"),\n",
    " 'models_dir': '/home/olimoyo/latent-metric-control/saved_models/{}'\n",
    "                   .format(\"test\"),\n",
    " 'n_batches': 32,\n",
    " 'device': 'cuda:0',\n",
    " 'n_trajs': 64,\n",
    " 'n_predictions': 11\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.dataset_path, 'rb') as f:\n",
    "    data = pkl.load(f)\n",
    "\n",
    "imgs_cached, actions, gt_state = data[0][:args.n_trajs], data[1][:args.n_trajs], data[2][:args.n_trajs]\n",
    "imgs_cached = imgs_cached.reshape(imgs_cached.shape[0], imgs_cached.shape[1], args.res, args.res, 3)\n",
    "imgs = torch.empty((imgs_cached.shape[0], imgs_cached.shape[1], 1, \n",
    "                    imgs_cached.shape[2], imgs_cached.shape[3]), device=args.device)\n",
    "actions = torch.from_numpy(actions).to(device=args.device)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    Normalize(mean=0.27, var=1.0 - 0.27) # 64x64\n",
    "    ])\n",
    "        \n",
    "for ii in range(imgs_cached.shape[0]):\n",
    "    for jj in range(imgs_cached.shape[1]):\n",
    "        imgs[ii, jj, :, :, :] = transform(imgs_cached[ii, jj, :, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from utils import load_models, frame_stack\n",
    "from argparse import Namespace\n",
    "import json\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "# Load hyperparameters from trained model\n",
    "for filedir in os.listdir(args.models_dir):\n",
    "    fullpath = os.path.join(args.models_dir, filedir)\n",
    "    if os.path.isdir(fullpath):\n",
    "        models[fullpath] = {}\n",
    "        with open(os.path.join(fullpath, 'hyperparameters.txt'), 'r') as fp:\n",
    "            models[fullpath]['hyperparameters'] = Namespace(**json.load(fp))\n",
    "            \n",
    "with torch.no_grad():\n",
    "    for path, model in models.items():\n",
    "        model_args = model['hyperparameters']\n",
    "        \n",
    "        enc, dec, dyn = load_models(path, model_args, mode='eval', device=args.device)\n",
    "        T = model_args.frame_stacks\n",
    "\n",
    "        z_all = torch.zeros((imgs.shape[0] * (imgs.shape[1] - T), model_args.dim_z)).to(device=args.device)\n",
    "        z_hat_all = torch.zeros((imgs.shape[0] * args.n_predictions, model_args.dim_z)).to(device=args.device)\n",
    "        gt_state_ = gt_state[:, T:]\n",
    "        gt_state_hat = gt_state[:, (T + 1):(T + 1 + args.n_predictions)]\n",
    "        \n",
    "        for ii in range(imgs.shape[0] // args.n_batches):\n",
    "            # Direct embedding\n",
    "            x = imgs[args.n_batches*ii:args.n_batches*(ii+1)]\n",
    "            x_s = frame_stack(x, frames=T)\n",
    "            z, mu_z, logvar_z = enc(x_s.reshape(-1, *x_s.shape[2:]))\n",
    "            z_all[z.shape[0]*ii:z.shape[0]*(ii+1)] = z\n",
    "            \n",
    "            # Roll-out or predictions embedding\n",
    "            z_hat =  torch.zeros((args.n_batches, args.n_predictions, model_args.dim_z)).to(device=args.device)\n",
    "            u_f = actions[args.n_batches*ii:args.n_batches*(ii+1), (T + 1):(T + 1 + args.n_predictions)]\n",
    "\n",
    "            x_i = imgs[args.n_batches*ii:args.n_batches*(ii+1), :(T + 1)]\n",
    "            x_i_s = frame_stack(x_i, frames=T)\n",
    "            z_i, mu_z_i, logvar_z_i = enc(x_i_s.reshape(-1, *x_i_s.shape[2:]))\n",
    "            var_z_i = torch.diag_embed(torch.exp(logvar_z_i))\n",
    "            h_i = None\n",
    "\n",
    "            for jj in range(args.n_predictions):\n",
    "                u_i = u_f[:, jj]\n",
    "                z_ip1, mu_z_ip1, var_z_ip1, h_ip1 = dyn(z_t=z_i, mu_t=mu_z_i, \n",
    "                                                        var_t=var_z_i, u=u_i, h=h_i, single=True)\n",
    "                z_hat[:, jj] = z_ip1[0]\n",
    "                z_i, mu_z_i, var_z_i, h_i = z_ip1[0], mu_z_ip1[0], var_z_ip1[0], h_ip1\n",
    "                \n",
    "            z_hat = z_hat.reshape(-1, *z_hat.shape[2:])\n",
    "            z_hat_all[z_hat.shape[0]*ii:z_hat.shape[0]*(ii+1)] = z_hat\n",
    "        \n",
    "        model['z_all'] = z_all.cpu().numpy()\n",
    "        model['z_hat_all'] = z_hat_all.cpu().numpy()\n",
    "        model['gt_state_hat'] = gt_state_hat.reshape(-1, *gt_state_hat.shape[2:])\n",
    "        model['gt_state'] = gt_state_.reshape(-1, *gt_state.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d(points3d, title, colour_scales, scale_labels):\n",
    "    n = len(colourscales)\n",
    "    fig = make_subplots(rows=1, cols=n, specs=[[{\"type\":\"scene\"} for _ in range(n)]])\n",
    "    \n",
    "    for ii, colourscale in enumerate(colourscales):\n",
    "        fig.add_trace(go.Scatter3d(x=points3d[:,0], y=points3d[:,1], z=points3d[:,2],\n",
    "                                   mode='markers',\n",
    "                                   marker=dict(size=1.5,\n",
    "                                               color=colourscale,        # set color to an array/list of desired values\n",
    "                                               colorbar=dict(title=scale_labels[ii], x=(ii + 1) * (1.0 / n)),  \n",
    "                                               colorscale='Viridis',   # choose a colorscale\n",
    "                                               opacity=0.75\n",
    "                                               )\n",
    "                                   ),\n",
    "                                   row=1, col=ii + 1\n",
    "                      )\n",
    "\n",
    "    layout = go.Layout(title=title, title_x=0.5, showlegend=False,\n",
    "                       xaxis=dict(zeroline=False, showgrid=True),\n",
    "                       yaxis=dict(zeroline=False, showgrid=True),\n",
    "                       scene_aspectmode='cube')\n",
    "    fig.update_layout(layout)\n",
    "    \n",
    "    for jj in range(n):\n",
    "        fig['layout']['scene{}'.format(jj + 1)].update(dict(\n",
    "            xaxis = dict(title='z₁', showticklabels=False),\n",
    "            yaxis = dict(title='z₂', showticklabels=False),\n",
    "            zaxis = dict(title='z₃', showticklabels=False),),\n",
    "        )\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "for k, model in models.items():\n",
    "    z = model['z_all']\n",
    "    th =  model['gt_state'][:,0]\n",
    "    thdot =  model['gt_state'][:,1]\n",
    "    colourscales = [th, thdot]\n",
    "    titles = [\"Ang. Pos.\", \"Ang. Vel.\"]\n",
    "    plot_3d(points3d=z, colour_scales=colourscales, scale_labels=titles, title=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
